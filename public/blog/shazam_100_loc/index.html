<!DOCTYPE html>
<html lang="en-us">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta http-equiv="X-Clacks-Overhead" content="GNU Terry Pratchett" />
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>Shazam algorithm in 100 lines of code | Slow Data</title>
<meta name="title" content="Shazam algorithm in 100 lines of code" />
<meta name="description" content="I recently saw this video on my YouTube landing page: some junior developer decided he would reimplement Shazam to keep himself busy and add something to his portfolio, since he can’t land a job. I decided to do it too, without looking at the video. After a few unsuccessful attempts, I gave up: I watched the video and read about the general algorithm ideas in a few different places. That guy&rsquo;s implementation is extremely cool, and definitely more complete than mine, it is a fully-featured (almost) deployment-ready piece of software.
But I&rsquo;m not trying to make any money out of this, I just want to understand how Shazam works: let&rsquo;s code Shazam in about 100 lines of Python." />
<meta name="keywords" content="Math,Signal analysis,Hashing,Algorithm,Music,Engineering," />


<meta property="og:url" content="http://localhost:1313/blog/shazam_100_loc/">
  <meta property="og:site_name" content="Slow Data">
  <meta property="og:title" content="Shazam algorithm in 100 lines of code">
  <meta property="og:description" content="I recently saw this video on my YouTube landing page: some junior developer decided he would reimplement Shazam to keep himself busy and add something to his portfolio, since he can’t land a job. I decided to do it too, without looking at the video. After a few unsuccessful attempts, I gave up: I watched the video and read about the general algorithm ideas in a few different places. That guy’s implementation is extremely cool, and definitely more complete than mine, it is a fully-featured (almost) deployment-ready piece of software. But I’m not trying to make any money out of this, I just want to understand how Shazam works: let’s code Shazam in about 100 lines of Python.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blog">
    <meta property="article:published_time" content="2025-12-20T12:30:29+01:00">
    <meta property="article:modified_time" content="2025-12-20T12:30:29+01:00">
    <meta property="article:tag" content="Math">
    <meta property="article:tag" content="Signal Analysis">
    <meta property="article:tag" content="Hashing">
    <meta property="article:tag" content="Algorithm">
    <meta property="article:tag" content="Music">
    <meta property="article:tag" content="Engineering">




  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Shazam algorithm in 100 lines of code">
  <meta name="twitter:description" content="I recently saw this video on my YouTube landing page: some junior developer decided he would reimplement Shazam to keep himself busy and add something to his portfolio, since he can’t land a job. I decided to do it too, without looking at the video. After a few unsuccessful attempts, I gave up: I watched the video and read about the general algorithm ideas in a few different places. That guy’s implementation is extremely cool, and definitely more complete than mine, it is a fully-featured (almost) deployment-ready piece of software. But I’m not trying to make any money out of this, I just want to understand how Shazam works: let’s code Shazam in about 100 lines of Python.">




  <meta itemprop="name" content="Shazam algorithm in 100 lines of code">
  <meta itemprop="description" content="I recently saw this video on my YouTube landing page: some junior developer decided he would reimplement Shazam to keep himself busy and add something to his portfolio, since he can’t land a job. I decided to do it too, without looking at the video. After a few unsuccessful attempts, I gave up: I watched the video and read about the general algorithm ideas in a few different places. That guy’s implementation is extremely cool, and definitely more complete than mine, it is a fully-featured (almost) deployment-ready piece of software. But I’m not trying to make any money out of this, I just want to understand how Shazam works: let’s code Shazam in about 100 lines of Python.">
  <meta itemprop="datePublished" content="2025-12-20T12:30:29+01:00">
  <meta itemprop="dateModified" content="2025-12-20T12:30:29+01:00">
  <meta itemprop="wordCount" content="3894">
  <meta itemprop="keywords" content="Math,Signal Analysis,Hashing,Algorithm,Music,Engineering">
<meta name="referrer" content="no-referrer-when-downgrade" />

  <style>
  :root {
    --width: 1024px;
    --font-main: Verdana, sans-serif;
    --font-secondary: Verdana, sans-serif;
    --font-scale: 1em;
    --background-color: #01242e;
    --heading-color: #eee;
    --text-color: #ddd;
    --link-color: #8cc2dd;
    --visited-color: #8b6fcb;
    --blockquote-color: #ccc;


  }

  @media (prefers-color-scheme: white) {
    :root {
      --background-color: #fff;
      --heading-color: #222;
      --text-color: #444;
      --link-color: #3273dc;
      --visited-color: #8b6fcb;
      --blockquote-color: #222;
    }
  }

  body {
    font-family: var(--font-secondary);
    font-size: var(--font-scale);
    margin: auto;
    padding: 20px;
    max-width: var(--width);
    text-align: left;
    background-color: var(--background-color);
    word-wrap: break-word;
    overflow-wrap: break-word;
    line-height: 1.5;
    color: var(--text-color);
  }

  h1,
  h2,
  h3,
  h4,
  h5,
  h6 {
    font-family: var(--font-main);
    color: var(--heading-color);
  }

  a {
    color: var(--link-color);
    cursor: pointer;
    text-decoration: none;
  }

  a:hover {
    text-decoration: underline;
  }

  nav a {
    margin-right: 8px;
  }

  strong,
  b {
    color: var(--heading-color);
  }

  button {
    margin: 0;
    cursor: pointer;
  }

  time {
    font-family: monospace;
    font-style: normal;
    font-size: 15px;
  }

  main {
    line-height: 1.6;
  }

  table {
    width: 100%;
  }

  hr {
    border: 0;
    border-top: 1px dashed;
  }

  img {
    max-width: 100%;
  }

  code {
    font-family: monospace;
    padding: 2px;
    border-radius: 3px;
  }

  blockquote {
    border-left: 1px solid #999;
    color: var(--blockquote-color);
    padding-left: 20px;
    font-style: italic;
  }

  footer {
    padding: 25px 0;
    text-align: center;
  }

  .title:hover {
    text-decoration: none;
  }

  .title h1 {
    font-size: 1.5em;
  }

  .inline {
    width: auto !important;
  }

  .highlight,
  .code {
    margin-block-start: 1em;
    margin-block-end: 1em;
    overflow-x: auto;
  }

  .highlight pre,
  .code pre {
    padding-left: 1em;
    padding-right: 1em;
    padding-top: 0;
    padding-bottom: 0;
    margin: 0;
    border: 0;
    border-radius: 5px;
    overflow-x: auto;
    overflow-y: hidden;
  }

   
  ul.blog-posts {
    list-style-type: none;
    padding: unset;
  }

  ul.blog-posts li {
    display: flex;
  }

  ul.blog-posts li span {
    flex: 0 0 130px;
  }

  ul.blog-posts li a:visited {
    color: var(--visited-color);
  }
</style>

    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>

<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['$', '$']]                  
    },
    loader:{
      load: ['ui/safe']
    },
  };
</script>
  
</head>

<body>
  <header><a href="/" class="title">
  <h2>Slow Data</h2>
</a>
<nav>
<a href="/blog/">Blog</a>

</nav>
</header>
  <main>

<h1>Shazam algorithm in 100 lines of code</h1>
<p>
  <i>
    <time datetime='2025-12-20'>
      20 Dec, 2025
    </time>
  </i>
</p>

<content>
  <p>I recently saw <a href="https://www.youtube.com/watch?v=a0CVCcb0RJM">this video</a> on my YouTube landing page: some junior developer decided he would reimplement Shazam to keep himself busy and add something to his portfolio, since he can’t land a job. I decided to do it too, without looking at the video. After a few unsuccessful attempts, I gave up: I watched the video and read about the general algorithm ideas in a few different places. That guy&rsquo;s <a href="https://github.com/cgzirim/seek-tune?tab=readme-ov-file">implementation</a> is extremely cool, and definitely more complete than mine, it is a fully-featured (almost) deployment-ready piece of software.
But I&rsquo;m not trying to make any money out of this, I just want to understand how Shazam works: let&rsquo;s code Shazam in about 100 lines of Python.</p>
<p>The teasing: It will be able to extremely confidently recognize songs from such samples, among ~100 songs<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p><audio controls preload="auto" src="/audios/noisy_cafe_crazy_in_love.wav"></audio>
<audio controls preload="auto" src="/audios/noisy_toxic.wav"></audio></p>
<h1 id="a-physics-crashcourse-a-lie-and-a-promise">A physics crashcourse, a lie and a promise</h1>
<p>Our goal is to design a fingerprinting algorithm for songs, so that even from an extremely partial and noisy sample from the song, we may recognize parts of its unique fingerprint and match it to the right song in our database. To design such a thing, we need to understand what is a <code>.wav</code> or <code>.mp3</code> file in a computer, and this is actually closely related to what &ldquo;sound&rdquo; means in physics.</p>
<h2 id="whats-a-sound-really-">What&rsquo;s a sound, really ?</h2>
<p>Wikipedia states that:</p>
<blockquote>
<p>In physics, sound is a vibration that propagates as an acoustic wave through a transmission medium such as a gas, liquid or solid. In human physiology and psychology, sound is the reception of such waves and their perception by the brain. Only acoustic waves that have frequencies lying between about 20 Hz and 20 kHz, the audio frequency range, elicit an auditory percept Sound waves above 20 kHz are known as ultrasound and are not audible to humans. Sound waves below 20 Hz are known as infrasound. Different animal species have varying hearing ranges, allowing some to even hear ultrasounds.</p>
</blockquote>
<p>What matters in that paragraph is that our human ears hear sounds by sensing variations of the air pressure. In Audacity (a free software for editing audio files), when you open a file, you may visualize it like this:</p>
<p><img src="https://manual.audacityteam.org/m/images/b/b7/multi_view_mono_default_50_50.png" alt="Soundwave and spectrogram"></p>
<p>In the top part, a fairly familiar sight: the x-axis is time and the y-axis is the amplitude, i.e the pressure. As we just said, what really matters is the variation of that amplitude, so when we&rsquo;re recording a sound numerically, we need to sample the air pressure very very often. Wikipedia states that we can hear sounds up to 20kHz, so we need atleast 20 000 samples per second ! Actually, to avoid <a href="https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem">aliasing</a> it is better to have atleast twice that, i.e 40kHz. In a computer, if we ignore compression to save memory, a sound will be represented as a header with some metadata (notably the duration, the sample rate and the number of channels) and then a big list of all these samples. This is exactly how the <a href="en.wikipedia.org/wiki/WAV"><code>.wav</code> file format</a> is designed.</p>
<p>Back to that image: in the bottom part, we see something completely different. The x-axis is still time, and the color is the intensity of the sound at a given time, but then what&rsquo;s the  y-axis ? The answer is frequency, in this case it seems to be varying between 0 and 12kHz, with most signal being below 2.6kHz. As I am more a mathematician than a physicist, I understand this through the following theorem from Fourier analysis:</p>
<blockquote>
<p>For $f: \mathbb{R} \to \mathbb{R}$ sufficiently smooth (for instance, $\mathcal{C}^1$ is enough) and $1$-periodic, there exists a unique sequence $(a_n)_{n \in \mathbb{Z}}$ such that </p>
$$f(x) = \sum_{n \in \mathbb{Z}} a_n e^{2 i \pi n x}$$<p>
Moreover the coefficients $a_n$, called the frequencies composing $f$, can be retrieved through the formula </p>
$$a_n = \int_0^1 f(x) e^{-2i \pi nx} \mathrm{d}x$$</blockquote>
<p>The second part of that statement is easy to deduce from the first, by swapping both integrals and using the identity $\int_0^1 e^{2 i \pi n x} = 0$ whenever $n \neq 0$. The first part requires some work and I we will not go down this rabbit hole. Going back to the physics, if we think of $f$ as representing a sound (that is the air pressure as a function of the time), we see that any (periodic, it will matter later) sound can be decomposed as a sum of pure trigonometric waves. Pure sin/cosine soundwaves are called pure tones in music, and they sound exactly like when you hit a single note on a piano.</p>
<h2 id="the-infamous-fft">The infamous FFT</h2>
<p>Leaving the physicist realm, we go back to our computers: given an audio file, we need a way to go from the amplitude representation to the frequency representation. The above theorem (up to discretization, i.e replacing integrals by sums over the points of the sampling grid), this amounts to computing enough fourier transforms, that is the above integrals <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>, which is about <code>2 * SAMPLE_RATE ^2 * DURATION_IN_SECONDS</code> operations. Even at the extremely low <code>SAMPLE_RATE = 12_000</code> for a 3 min audio, we would need 25 920 000 000 operations. Luckily for us, there is a clever algorithm designed in a divide-and-conquer fashion that speeds up this process significantly and runs in quasi-linear time: the Fast Fourier Transform (FFT). For a fairly clear explanation of the algorithm, see <a href="https://en.wikipedia.org/wiki/Cooley%E2%80%93Tukey_FFT_algorithm#The_radix-2_DIT_case">this wikipedia page</a>.</p>
<h2 id="spectrograms">Spectrograms</h2>
<p>I actually put something under the rug earlier, when I talked about that frequency sound representation (which is called a <em>spectrogram</em> btw). We have a tool (the Fourier transform) to extract frequencies from a sound, but how do we extract frequencies for a sound.. at a given time $t_0$. It turns out we cannot do that, so we do the next best thing: we pick a very small window $[t_0 - \varepsilon, t_0 + \varepsilon]$ and use the Fourier Transform to extract the frequencies of that new sound. Sadly, Fourier transform is designed to work on periodic signal and there is no reason to believe that sound will be periodic. The discontinuities at the edges introduce aliasing defects, and to avoid that we use a <a href="https://en.wikipedia.org/wiki/Window_function">smoothing window function</a> $\omega(t)$ that is supported on $[t_0 - \varepsilon, t_0 + \varepsilon]$ and zero elsewhere, and we take the Fourier transform of the sound multiplied by this window function over a larger time frame. This avoids aliasing almost completely, at the expense of introducing parasitic frequencies that come from the window function.</p>
<h2 id="listing-the-dependencies">Listing the dependencies</h2>
<p>In essence, the algorithm is fairly easy to map into pure, clean and simple Python, but it will never be fast enough for comfortable use. I wanted to be able to quickly iterate over changes and waiting 20 secondes every time I need the frequency representation of my 3 minute audio was not an option, so I used the <a href="https://librosa.org/doc/latest/index.html">librosa</a> library in Python. Similarly, Audio files I/O is also handled by librosa, even though <code>.wav</code> is fairly easy and I could have just parsed it by hand. For speed, comfort and many other very good reasons, I also use <a href="https://numpy.org/">numpy</a>.</p>
<p>That&rsquo;s it, we are set up, no more new specific theory, no more dependencies. The rest is really about 100 line of codes of pure Python, and a working reasonable proof-of-concept Shazam clone that works reasonably fast with very good noise and distortion resistance (see below for some tests). No magic theorem or unknown data structure, that&rsquo;s a promise !</p>
<h1 id="the-strategy">The strategy</h1>
<p>Here&rsquo;s a rough outline of we will do for each audio we want to be able to recognize:</p>
<ul>
<li>Preprocess our audio: resample it to a fixed sample rate, average across channels to transform stereo signals to mono</li>
<li>Apply the procedure explained above to get a spectrogram out of our signal</li>
<li>Split the spectrogram into a few frequency bands (pretty much given by <a href="https://en.wikipedia.org/wiki/Octave">octaves</a>), to avoid dominance in magnitude by the low bass that are often amplified in musical post-processing<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>.</li>
<li>For each of these bands, store the local magnitude peaks in a big database, that is store triples <code>(peak_frequency, sample_index, music_name)</code>. We&rsquo;ll make the meaning of &ldquo;local magnitude peak&rdquo; more precise below, but you can think of it as &ldquo;the fundamental note played at a given moment in a given octave&rdquo;.</li>
</ul>
<p>Then, when we&rsquo;re querying the database with a given noisy recording, we apply the same steps but instead of storing the peaks in the database, we collect all the matching peak_frequencies in the database and then we compare the sample indexes of the matches against the sample indexes of the noisy recording. If there is enough match for a given song and they are coherent in timing, then we found a very likely match.</p>
<h1 id="the-data">The data</h1>
<p>I used the yt-dlp library/command-line tool to download a few famous musical <code>.wav</code> files from YouTube and put them in a <code>audios/</code> folder at the root of the project. The list is composed of about 100 very famous songs ChatGPT put together + 3 randoms songs I added in there (can you find them ?). Note that I downloaded everything as <code>.wav</code> files because I wanted everything to be as simple as possible, but in real life you would definitely use <code>.mp3</code> files.</p>
<details style="opacity: 0.8;">
    <summary>The quick&amp;dirty download script</summary>
    <div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> yt_dlp
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> pathlib <span style="color:#f92672">import</span> Path
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">download_batch_as_wav</span>(queries, output_dir):
</span></span><span style="display:flex;"><span>    output_dir <span style="color:#f92672">=</span> Path(output_dir)
</span></span><span style="display:flex;"><span>    output_dir<span style="color:#f92672">.</span>mkdir(parents<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, exist_ok<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    base_opts <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;format&#34;</span>: <span style="color:#e6db74">&#34;bestaudio/best&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;noplaylist&#34;</span>: <span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;default_search&#34;</span>: <span style="color:#e6db74">&#34;ytsearch1&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;postprocessors&#34;</span>: [
</span></span><span style="display:flex;"><span>            {
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;key&#34;</span>: <span style="color:#e6db74">&#34;FFmpegExtractAudio&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;preferredcodec&#34;</span>: <span style="color:#e6db74">&#34;wav&#34;</span>,
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>        ],
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;postprocessor_args&#34;</span>: [<span style="color:#e6db74">&#34;-ar&#34;</span>, <span style="color:#e6db74">&#34;12000&#34;</span>],
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;quiet&#34;</span>: <span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> query <span style="color:#f92672">in</span> queries:
</span></span><span style="display:flex;"><span>        filename <span style="color:#f92672">=</span> query<span style="color:#f92672">.</span>lower()<span style="color:#f92672">.</span>replace(<span style="color:#e6db74">&#39; - &#39;</span>, <span style="color:#e6db74">&#39;__&#39;</span>)<span style="color:#f92672">.</span>replace(<span style="color:#e6db74">&#39; &#39;</span>, <span style="color:#e6db74">&#39;_&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        ydl_opts <span style="color:#f92672">=</span> base_opts <span style="color:#f92672">|</span> {
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;outtmpl&#34;</span>: str(output_dir <span style="color:#f92672">/</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>filename<span style="color:#e6db74">}</span><span style="color:#e6db74">.%(ext)s&#34;</span>)
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> yt_dlp<span style="color:#f92672">.</span>YoutubeDL(ydl_opts) <span style="color:#66d9ef">as</span> ydl:
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Downloading: </span><span style="color:#e6db74">{</span>query<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>            ydl<span style="color:#f92672">.</span>download([query])
</span></span></code></pre></div></div>
</details>
<details style="opacity: 0.8;">
    <summary>The list of songs I used</summary>
    <div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>songs <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Bohemian Rhapsody - Queen&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Imagine - John Lennon&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Billie Jean - Michael Jackson&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Hey Jude - The Beatles&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Like a Rolling Stone - Bob Dylan&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Smells Like Teen Spirit - Nirvana&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Hotel California - Eagles&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Sweet Child O&#39; Mine - Guns N&#39; Roses&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Stairway to Heaven - Led Zeppelin&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;I Will Always Love You - Whitney Houston&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Thriller - Michael Jackson&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Rolling in the Deep - Adele&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Someone Like You - Adele&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Purple Rain - Prince&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Let It Be - The Beatles&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Yesterday - The Beatles&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Hallelujah - Leonard Cohen&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Uptown Funk - Mark Ronson ft. Bruno Mars&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Shape of You - Ed Sheeran&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Blinding Lights - The Weeknd&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Wonderwall - Oasis&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Lose Yourself - Eminem&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;What a Wonderful World - Louis Armstrong&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Comfortably Numb - Pink Floyd&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Born to Run - Bruce Springsteen&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Take On Me - a-ha&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Every Breath You Take - The Police&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Africa - Toto&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Justin Timberlake - Can&#39;t Stop The Feeling&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Livin&#39; on a Prayer - Bon Jovi&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;I Want It That Way - Backstreet Boys&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Single Ladies - Beyoncé&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Crazy in Love - Beyoncé&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;No Woman No Cry - Bob Marley&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Redemption Song - Bob Marley&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Superstition - Stevie Wonder&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Isn&#39;t She Lovely - Stevie Wonder&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Karma Police - Radiohead&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Creep - Radiohead&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Firework - Katy Perry&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Bad Romance - Lady Gaga&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Poker Face - Lady Gaga&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Take Me to Church - Hozier&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Thinking Out Loud - Ed Sheeran&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;All of Me - John Legend&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Clocks - Coldplay&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Viva La Vida - Coldplay&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Fix You - Coldplay&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Paramore - Misery Business&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;My Heart Will Go On - Celine Dion&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Toxic - Britney Spears&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Baby One More Time - Britney Spears&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Smooth - Santana ft. Rob Thomas&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;With or Without You - U2&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Beautiful Day - U2&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;September - Earth, Wind &amp; Fire&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Stayin&#39; Alive - Bee Gees&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Dancing Queen - ABBA&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Mamma Mia - ABBA&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Take Me Home, Country Roads - John Denver&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;American Pie - Don McLean&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Dream On - Aerosmith&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Back in Black - AC/DC&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Thunderstruck - AC/DC&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Eye of the Tiger - Survivor&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Nothing Else Matters - Metallica&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Enter Sandman - Metallica&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Radioactive - Imagine Dragons&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Believer - Imagine Dragons&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Despacito - Luis Fonsi ft. Daddy Yankee&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Old Town Road - Lil Nas X&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Bad Guy - Billie Eilish&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Rolling Stone - The Weeknd&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;MPH - Cadence&#34;</span>, 
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;God&#39;s Plan - Drake&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;One Dance - Drake&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Lose Yourself to Dance - Daft Punk&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Get Lucky - Daft Punk&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Call Me Maybe - Carly Rae Jepsen&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Fireflies - Owl City&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Shake It Off - Taylor Swift&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Blank Space - Taylor Swift&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;We Will Rock You - Queen&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;We Are the Champions - Queen&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Sweet Caroline - Neil Diamond&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Take Me Out - Franz Ferdinand&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Mr. Brightside - The Killers&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Seven Nation Army - The White Stripes&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Paint It Black - The Rolling Stones&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Gimme Shelter - The Rolling Stones&#34;</span>
</span></span><span style="display:flex;"><span>]
</span></span></code></pre></div></div>
</details>
<p>For benchmarking, I also recorded with my phone in noisy environments/squashed together through scripting and audacity diverses kind of noisy recordings, either by adding a noisy cafe environment, adding gaussian noise or recording over with my phone and talking over it. All of these got recognized by the algorithm, needing at most 20 seconds of recording for the most noisy environments (approx. signal to noise ratio equal to 1).</p>
<h1 id="the-code">The code</h1>
<h2 id="building-the-database">Building the database</h2>
<p>Let&rsquo;s start with a rough pseudo-code:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">build_database</span>(audios: list[(str, str)]):
</span></span><span style="display:flex;"><span>    database <span style="color:#f92672">=</span> empty_database()
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> (audio_path, tag) <span style="color:#f92672">in</span> audios:
</span></span><span style="display:flex;"><span>        audio <span style="color:#f92672">=</span> load_audio(audio_path)
</span></span><span style="display:flex;"><span>        spectrogram <span style="color:#f92672">=</span> build_spectrogram(audio)
</span></span><span style="display:flex;"><span>        bands <span style="color:#f92672">=</span> get_bands(spectrogram)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> band <span style="color:#f92672">in</span> bands:
</span></span><span style="display:flex;"><span>            (peaks, magnitudes, sample_indexes) <span style="color:#f92672">=</span> get_peaks(band)
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> (peak, magnitude, sample_idx) <span style="color:#f92672">in</span> zip(peaks, magnitudes, sample_indexes):
</span></span><span style="display:flex;"><span>                database[peak]<span style="color:#f92672">.</span>append((tag, sample_idx))
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> database
</span></span></code></pre></div><p>Let&rsquo;s implement that line by line. For the database we use a <code>collections.defaultdict</code>, which is simply a hashmap with a default value in case the key does not exist. In this case, the default value is an empty list.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> collections <span style="color:#f92672">import</span> defaultdict
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">build_database</span>(audios):
</span></span><span style="display:flex;"><span>    database <span style="color:#f92672">=</span> defaultdict(list)
</span></span></code></pre></div><p>We load the audio with</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>audio, _ <span style="color:#f92672">=</span> librosa<span style="color:#f92672">.</span>load(audio_path, sr<span style="color:#f92672">=</span>SAMPLE_RATE, mono<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>float32)
</span></span></code></pre></div><p>There&rsquo;s actually <em>lot</em> happening here, so let&rsquo;s go through the parameters one by one:</p>
<ul>
<li>We load the audio by giving its path to librosa</li>
<li>We force librosa to resample<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> it to the given <code>SAMPLE_RATE</code> constant. The reason we resample is 1) we want all our audios to have the same frequency bands and 2) to reduce the computational load 3) the main melodic frequencies lie below 4kHz, so we don&rsquo;t need more than twice the samples per seconds to hear them without aliasing. YouTube audios have a default sample rate of 44kHz, definitely too much for signal analysis. We set <code>SAMPLE_RATE = 8_000</code>. There will be a lot of tunable constants like these along the way so we&rsquo;ll add them one after another at the beginning of the file.</li>
<li>We ask it to give a mono (i.e 1-dimensional, as opposed to hearing different things in both ears when you wear headphones for instance). This is simply done by averaging over all the channels.</li>
<li>Finally, we ask for our signal to be read as 32bit floating points numbers.</li>
</ul>
<p>The second argument we ignore with <code>_</code> is the sample rate, which is useful if you let the <code>sr</code> parameter unspecified and work with files coming with distinct sample rates: not our case.</p>
<p>Next, we need the spectrogram of our signal. As explained above, we need to take the fft of our signal   times a smoothing function supported on a small subset. We could define such a function like this</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">build_spectrogram</span>(audio, window_size, hop_length, smoothing_window):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    smoothing_window is a window_size-sized array
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    frames <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">+</span> (len(audio) <span style="color:#f92672">-</span> window_size) <span style="color:#f92672">//</span> hop_length 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    spectrogram <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros((frames, <span style="color:#ae81ff">1</span> <span style="color:#f92672">+</span> window_size <span style="color:#f92672">//</span> <span style="color:#ae81ff">2</span>), dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>complex)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">0</span>, len(audio), hop_length)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> i <span style="color:#f92672">+</span> window_size <span style="color:#f92672">&gt;=</span> len(audio):
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>        spectrogram[k, :] <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>fft<span style="color:#f92672">.</span>rfft(audio[i:i<span style="color:#f92672">+</span>window_size] <span style="color:#f92672">*</span> smoothing_window)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>abs(spectrogram)
</span></span></code></pre></div><p>We make use of numpy&rsquo;s real fft function<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>. Note that we take the absolute value since we are only really interested in the magnitude of the signal, not the phase.</p>
<p>The nice thing about librosa is that it already provides a function that builds a spectrogram out of our audio, so that we don&rsquo;t have to handle the sliding window ourselves (and make it a speed bottleneck). It is called <code>stft</code> for Short-Time Fourier Transform</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>spectrogram <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>abs(librosa<span style="color:#f92672">.</span>stft(audio, n_fft<span style="color:#f92672">=</span>WINDOW_SIZE, hop_length<span style="color:#f92672">=</span>HOP_LENGTH, window<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;hamming&#34;</span>))
</span></span></code></pre></div><p>For the constants, we set at the beginning of the file <code>WINDOW_SIZE = 2048, HOP_LENGTH = 256</code> which are approximately equal to <code>250ms</code> and <code>25ms</code>, given a sampling_rate of <code>8000</code>. The <code>window=&quot;hamming&quot;</code> parameter tells librosa to use a Hamming smoothing window function. Why this function and not another one  ? It seems to be the one that better preserves peak frequencies. I checked that by drawing the spectrograms of a few sums of sinusoids with matplotlib.</p>
<p>To get a better feel as to what we&rsquo;re doing here, Here is the spectrogram of the 20 first seconds of Get Lucky from the Daft Punk, first built with a hamming window and then without any smoothing window (i.e a rectangular window). We can clearly see the rough cut-offs created by the aliasing in the second picture.
<img src="/images/spectrogram_get_lucky.png" alt="A spectrogram with a hamming window">
<img src="/images/spectrogram_no_window_get_lucky.png" alt="A spectrogram with no windowing"></p>
<p>Now we want to split our spectrogram into frequency bands. Frequencies below 80Hz can safely be dropped since they&rsquo;ll often contain more noise than signal, and anything above 1300Hz is already extremely high. We thus define the following bands: 80-160Hz, 160-320Hz, 320-640Hz, 640-1280Hz, 1280-4000Hz. We&rsquo;ll need to index our spectrogram, i.e map these frequencies to actual spectrogram indexes, and so we define</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>STFT_RESOLUTION <span style="color:#f92672">=</span> SAMPLE_RATE <span style="color:#f92672">/</span> WINDOW_SIZE
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>BAND_THRESHOLDS <span style="color:#f92672">=</span> [<span style="color:#ae81ff">80</span>, <span style="color:#ae81ff">160</span>, <span style="color:#ae81ff">320</span>, <span style="color:#ae81ff">640</span>, <span style="color:#ae81ff">1280</span>, SAMPLE_RATE <span style="color:#f92672">//</span> <span style="color:#ae81ff">2</span>]
</span></span><span style="display:flex;"><span>BAND_INDEXES <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    (
</span></span><span style="display:flex;"><span>        round(BAND_THRESHOLDS[i] <span style="color:#f92672">/</span> STFT_RESOLUTION),
</span></span><span style="display:flex;"><span>        round(BAND_THRESHOLDS[i <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>] <span style="color:#f92672">/</span> STFT_RESOLUTION),
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(BAND_THRESHOLDS)<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>]
</span></span></code></pre></div><p>In the <code>build_database</code> function we define</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    bands <span style="color:#f92672">=</span> [spectrogram[start:end, :] <span style="color:#66d9ef">for</span> (start, end) <span style="color:#f92672">in</span> BAND_INDEXES]
</span></span></code></pre></div><p>Now to compute the peaks, we need to define what&rsquo;s a peak: a peak in a band is a frequency whose magnitude is maximal among a rectangular neighborhood of size <code>FREQ_NGHBR x TIME_NGHBR</code>. We think of each band as an image and apply a <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.maximum_filter.html">maximum filter</a> to it, then compare it with the original image to get a boolean array of peak locations. We remove the peaks whose intensity lie below the bottom <code>INTENSITY_THRESHOLD</code>% of points in the band, as they are likely to be noise. Finally, we reindex the frequency indexes of the peaks to go from band index to global (spectrogram) index and store all of that in a.. list of tuple of lists.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> scipy.ndimage <span style="color:#f92672">import</span> maximum_filter
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>peaks <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> band_idx, band <span style="color:#f92672">in</span> enumerate(bands): 
</span></span><span style="display:flex;"><span>    local_maximums <span style="color:#f92672">=</span> band <span style="color:#f92672">==</span> maximum_filter(band, size<span style="color:#f92672">=</span>(FREQ_NGHBR, TIME_NGHBR))
</span></span><span style="display:flex;"><span>    thresh <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>percentile(band, INTENSITY_THRESHOLD)
</span></span><span style="display:flex;"><span>    strong <span style="color:#f92672">=</span> band <span style="color:#f92672">&gt;=</span> thresh
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    (band_freq_indexes, sample_indexes) <span style="color:#f92672">=</span> (local_maximums <span style="color:#f92672">&amp;</span> strong)<span style="color:#f92672">.</span>nonzero()
</span></span><span style="display:flex;"><span>    global_freq_indexes <span style="color:#f92672">=</span> band_freq_indexes <span style="color:#f92672">+</span> BAND_INDEXES[band_idx][<span style="color:#ae81ff">0</span>] <span style="color:#75715e"># </span>
</span></span><span style="display:flex;"><span>    peaks<span style="color:#f92672">.</span>append(global_freq_indexes, sample_indexes)
</span></span></code></pre></div><p>We also set the constants</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>INTENSITY_THRESHOLD <span style="color:#f92672">=</span> <span style="color:#ae81ff">95</span>
</span></span><span style="display:flex;"><span>FREQ_NGHBR <span style="color:#f92672">=</span> <span style="color:#ae81ff">30</span>
</span></span><span style="display:flex;"><span>TIME_NGHBR <span style="color:#f92672">=</span> <span style="color:#ae81ff">15</span>
</span></span></code></pre></div><p>I have no strong reason for these numerical choices, they worked correctly but there&rsquo;s probably a lot of fine-tuning to be done on these. Finally, we iterate over this list of list and append each peak in the database dictionary, with the additional information of the timing of the ping (the <code>sample_index</code>) and the <code>tag</code> of the song, and we return the database at the end. Here is the final code for the database</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">bands_peaks</span>(spec):
</span></span><span style="display:flex;"><span>    bands <span style="color:#f92672">=</span> [spec[start:end, :] <span style="color:#66d9ef">for</span> (start, end) <span style="color:#f92672">in</span> BAND_INDEXES]
</span></span><span style="display:flex;"><span>    peaks <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> band_idx, band <span style="color:#f92672">in</span> enumerate(bands): 
</span></span><span style="display:flex;"><span>        local_maximums <span style="color:#f92672">=</span> band <span style="color:#f92672">==</span> maximum_filter(band, size<span style="color:#f92672">=</span>(FREQ_NGHBR, TIME_NGHBR))
</span></span><span style="display:flex;"><span>        thresh <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>percentile(band, <span style="color:#ae81ff">95</span>)
</span></span><span style="display:flex;"><span>        strong <span style="color:#f92672">=</span> band <span style="color:#f92672">&gt;=</span> thresh
</span></span><span style="display:flex;"><span>        (band_freq_indexes, sample_indexes) <span style="color:#f92672">=</span> (local_maximums <span style="color:#f92672">&amp;</span> strong)<span style="color:#f92672">.</span>nonzero()
</span></span><span style="display:flex;"><span>        global_freq_indexes <span style="color:#f92672">=</span> band_freq_indexes <span style="color:#f92672">+</span> BAND_INDEXES[band_idx][<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>        peaks<span style="color:#f92672">.</span>append((global_freq_indexes, sample_indexes))
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> peaks
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">build_database</span>(audios, path<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;database.json&#34;</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> open(path, <span style="color:#e6db74">&#34;r&#34;</span>) <span style="color:#66d9ef">as</span> db:
</span></span><span style="display:flex;"><span>            database <span style="color:#f92672">=</span> json<span style="color:#f92672">.</span>load(db)
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># Integers keys got converted to strings during json serialization</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> defaultdict(list, {int(k):v <span style="color:#66d9ef">for</span> k,v <span style="color:#f92672">in</span> database<span style="color:#f92672">.</span>items()})
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">except</span> <span style="color:#a6e22e">FileNotFoundError</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">pass</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    database <span style="color:#f92672">=</span> defaultdict(list)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> (audio_path, tag) <span style="color:#f92672">in</span> audios:
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Adding </span><span style="color:#e6db74">{</span>tag<span style="color:#e6db74">}</span><span style="color:#e6db74"> to database&#34;</span>)
</span></span><span style="display:flex;"><span>        audio, _ <span style="color:#f92672">=</span> librosa<span style="color:#f92672">.</span>load(audio_path, sr<span style="color:#f92672">=</span>SAMPLE_RATE, mono<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>float32)
</span></span><span style="display:flex;"><span>        spectrogram <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>abs(librosa<span style="color:#f92672">.</span>stft(audio, n_fft<span style="color:#f92672">=</span>WINDOW_SIZE, hop_length<span style="color:#f92672">=</span>HOP_LENGTH, window<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;hamming&#34;</span>))
</span></span><span style="display:flex;"><span>        peaks <span style="color:#f92672">=</span> bands_peaks(spectrogram)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> freq_indexes, sample_indexes <span style="color:#f92672">in</span> peaks:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> freq, sample <span style="color:#f92672">in</span> zip(freq_indexes, sample_indexes):
</span></span><span style="display:flex;"><span>                database[int(freq)]<span style="color:#f92672">.</span>append((int(sample), tag))
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> open(path, <span style="color:#e6db74">&#39;w&#39;</span>) <span style="color:#66d9ef">as</span> file:
</span></span><span style="display:flex;"><span>        json<span style="color:#f92672">.</span>dump(database, file, indent<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> database
</span></span></code></pre></div><p>I extracted the <code>bands_peaks</code> logic in another function since we&rsquo;ll reuse it in the next section. I also added some basic saving/loading of the database in a JSON file, since recomputing the database everytime is annoying.</p>
<h2 id="matching-a-recording">Matching a recording</h2>
<p>To match a recording to the database we built, we first compute its spectrogram and extract the band peaks. Then, for each of the recording&rsquo;s peak, we compare the matching frequencies in the database and we compute the offset (time/sample_index difference) between the database peak and the recording peak. If a given song has enough matching offsets, we found a likely match !</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> collections <span style="color:#f92672">import</span> Counter
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Some testing showed allow for a little margin for the scoring helped getting more robust scores, </span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># since on noisy data the magnitude peaks may happen a few m.s before/after the peak on the original audio</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">score_offsets</span>(offsets, window<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>):    
</span></span><span style="display:flex;"><span>    offsets_counts <span style="color:#f92672">=</span> Counter()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> t_audio, t_query <span style="color:#f92672">in</span> offsets:
</span></span><span style="display:flex;"><span>        offset <span style="color:#f92672">=</span> t_audio <span style="color:#f92672">-</span> t_query
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(max(<span style="color:#ae81ff">0</span>, offset <span style="color:#f92672">-</span> window), offset <span style="color:#f92672">+</span> window <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>):
</span></span><span style="display:flex;"><span>            offsets_counts[i] <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>    _dominant_offset, count <span style="color:#f92672">=</span> offsets_counts<span style="color:#f92672">.</span>most_common(<span style="color:#ae81ff">1</span>)[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> count
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">match_recording</span>(database, recording_path):
</span></span><span style="display:flex;"><span>        recording, _ <span style="color:#f92672">=</span> librosa<span style="color:#f92672">.</span>load(recording_path, sr<span style="color:#f92672">=</span>SAMPLE_RATE, mono<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>float32)
</span></span><span style="display:flex;"><span>        spectrogram <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>abs(librosa<span style="color:#f92672">.</span>stft(recording, n_fft<span style="color:#f92672">=</span>WINDOW_SIZE, hop_length<span style="color:#f92672">=</span>HOP_LENGTH, window<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;hamming&#34;</span>))
</span></span><span style="display:flex;"><span>        rec_peaks <span style="color:#f92672">=</span> bands_peaks(spectrogram)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        offsets <span style="color:#f92672">=</span> defaultdict(list)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> rec_freq_peaks, rec_sample_peaks <span style="color:#f92672">in</span> rec_peaks:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> rec_freq_idx, rec_sample_idx <span style="color:#f92672">in</span> zip(rec_freq_peaks, rec_sample_peaks):
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">for</span> db_sample_idx, tag <span style="color:#f92672">in</span> database[rec_freq_idx]:
</span></span><span style="display:flex;"><span>                    offsets[tag]<span style="color:#f92672">.</span>append((db_sample_idx, rec_sample_idx))
</span></span><span style="display:flex;"><span>        scores <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> tag, offsets_array <span style="color:#f92672">in</span> offsets<span style="color:#f92672">.</span>items():
</span></span><span style="display:flex;"><span>            score <span style="color:#f92672">=</span> score_offsets(offsets_array)
</span></span><span style="display:flex;"><span>            scores<span style="color:#f92672">.</span>append((tag,score))
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> sorted(scores, key<span style="color:#f92672">=</span> <span style="color:#66d9ef">lambda</span> x: x [<span style="color:#ae81ff">1</span>], reverse<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span></code></pre></div><h1 id="final-results-benchmarks-and-last-words">Final results, benchmarks and last words</h1>
<p>The full code is available <a href="https://github.com/Shika-B/shazam-in-100-loc">here, on GitHub</a>, without the songs since they&rsquo;re obviously too large, but the download script is available for the songs. I also included the 2 samples I showed earlier, but test it with your own samples also! Including imports, constants definition and the pretty printing of the results, we are at 107 lines of code, with only about 50 lines of logic: I kept up on that promise!</p>
<p>Here are the results with the 2 samples I shared at the beginning of the post. I feel like that&rsquo;s pretty solid, given the amount of noise.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>Querying file samples<span style="color:#f92672">/</span>noisy_sample2__britney_spears__toxic<span style="color:#f92672">.</span>wav
</span></span><span style="display:flex;"><span>Top <span style="color:#ae81ff">2</span> scores
</span></span><span style="display:flex;"><span>Song toxic__britney_spears scored <span style="color:#ae81ff">44</span>
</span></span><span style="display:flex;"><span>Song every_breath_you_take__the_police scored <span style="color:#ae81ff">19</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">-----------------------------------------------------</span>
</span></span><span style="display:flex;"><span>Querying file samples<span style="color:#f92672">/</span>noisy_cafe__beyonce__crazy_in_love<span style="color:#f92672">.</span>wav
</span></span><span style="display:flex;"><span>Top <span style="color:#ae81ff">2</span> scores
</span></span><span style="display:flex;"><span>Song crazy_in_love__beyoncé scored <span style="color:#ae81ff">558</span>
</span></span><span style="display:flex;"><span>Song lose_yourself__eminem scored <span style="color:#ae81ff">31</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">-----------------------------------------------------</span>
</span></span></code></pre></div><p>Many improvements are possible:</p>
<ul>
<li>All of the matching is pretty fast but could be made <em>significantly</em> faster by using pairs of temporally close peaks instead of singles peaks as keys for the database. That would drastically reduce the number of useless matches.</li>
<li>All these arbitrary defined constants could be tuned to better match the reality of noisy musics we hear outside</li>
<li>We could make things faster by first trying to use only the first 5 seconds of the recording, then the 10 first seconds etc, as the real Shazam does. Often the audio will be clear enough that 5 seconds will.
etc.</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>The algorithm could handle a lot more songs in the database, the bottleneck really is that I did not download more songs from YouTube because of the timeout yt-dlp enforces&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>In the discretized case we are concerned with, I actually mean computing enough sums&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Because the human ear hears high frequencies before the low ones.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>Downsampling by an integer factor of $k$ should be easy: keep samples that are at indexes a multiple of $k$. Sadly, this introduce aliasing so we need to first filter higher frequencies before doing that, by applying a low-pass filter. Nothing unmanageable, but since this is all done by librosa automatically, we don&rsquo;t need to be concerned with that.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Note the spectrogram has shape <code>(1 + WINDOW_SIZE // 2, number_of_frames)</code>, where the number of frames depends on hop_length, because on a real signal with $n$ samples, rfft returns $\lfloor n / 2 \rfloor + 1$ frequency bins. See <a href="https://numpy.org/doc/stable/reference/generated/numpy.fft.rfft.html">the note here</a>&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>

</content>



<p>
  
  <a href="http://localhost:1313/tags/math/">#Math</a>
  
  <a href="http://localhost:1313/tags/signal-analysis/">#Signal Analysis</a>
  
  <a href="http://localhost:1313/tags/hashing/">#Hashing</a>
  
  <a href="http://localhost:1313/tags/algorithm/">#Algorithm</a>
  
  <a href="http://localhost:1313/tags/music/">#Music</a>
  
  <a href="http://localhost:1313/tags/engineering/">#Engineering</a>
  
</p>

  </main>
  <footer>Made with <a href="https://github.com/janraasch/hugo-bearblog/">Hugo ʕ•ᴥ•ʔ Bear</a>
</footer>

  
</body>

</html>
